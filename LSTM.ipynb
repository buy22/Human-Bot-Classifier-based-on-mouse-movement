{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29e8c9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40bd4e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 40\n",
    "human_ratio = 0.8\n",
    "bot_ratio = 0.2\n",
    "def data_handler_VAR(data, max_length = length):\n",
    "    d = np.zeros((len(data), max_length, 2))\n",
    "    for line in range(len(data)):\n",
    "        tmp = data[line]\n",
    "        l = len(tmp)\n",
    "        if l < max_length:\n",
    "            for i in range(max_length-l):\n",
    "                tmp.append(data[line][-1])\n",
    "        else:\n",
    "            tmp = tmp[:max_length]\n",
    "        d[line,::] = np.array(tmp)\n",
    "    return d\n",
    "\n",
    "def read_human(path='Mousecollector/records1.txt'):\n",
    "    train = pd.read_csv(path, sep=' ', header=None, encoding='utf-8', names=['data'])\n",
    "    data = train['data'].apply(lambda x: [list(map(float, point.split(','))) for point in x.split(';')])\n",
    "    return data_handler_VAR(data[:int(len(data)*human_ratio)]), data_handler_VAR(list(data[int(len(data)*human_ratio):]))\n",
    "\n",
    "def read_bot(path='data/gc2.csv', return_original = False):\n",
    "    train = pd.read_csv(path, sep=' ', header=None, encoding='utf-8', names=['id','data','_','1','end'])\n",
    "    data = train['data'].apply(lambda x: [list(map(float, point.split(';'))) for idx, point in enumerate(x.split(',')) if idx % 2 == 0][2:-2])\n",
    "    return data_handler_VAR(data[:int(len(data)*bot_ratio)]), data_handler_VAR(list(data[int(len(data)*bot_ratio):]))\n",
    "\n",
    "def read_data():\n",
    "    a, c = read_human() \n",
    "    b, d = read_bot()\n",
    "    return np.append(a, b, axis=0), a.shape[0], b.shape[0], np.append(c, d, axis=0), c.shape[0], d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25a8680e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trains, n_human1, n_bot1, tests, n_human2, n_bot2  = read_data()\n",
    "train_labels = np.array([0]*n_human1 + [1]*n_bot1).reshape((n_human1+n_bot1, 1))\n",
    "test_labels = np.array([0]*n_human2 + [1]*n_bot2).reshape((n_human2+n_bot2, 1))\n",
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b9215a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = trains.shape[1], trains.shape[2], train_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78c0edf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100)               41200     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41,301\n",
      "Trainable params: 41,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(n_timesteps, n_features)))\n",
    "#model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdd9d7c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbose, epochs, batch_size = 0, 32, 64\n",
    "model.fit(trains, train_labels, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(trains, train_labels, batch_size=batch_size, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d82e8d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(tests, test_labels, batch_size=batch_size, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b400ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing on the old 3000 data entries\n",
    "def read_old_data(path='data/dsjtzs_txfz_training.txt'):\n",
    "    train = pd.read_csv(path, sep=' ', header=None, encoding='utf-8', names=['id', 'data', 'target', 'label'])\n",
    "    data = train['data'].apply(lambda x: [list(map(float, point.split(',')))[:-1] for point in x.split(';')[:-1]])\n",
    "    label = list(train['label'])\n",
    "    \n",
    "    sep = label.index(0)\n",
    "    human = data[:sep]\n",
    "    bot = list(data[sep:])\n",
    "    return np.append(data_handler_VAR(human), data_handler_VAR(bot), axis=0),  np.array(label).reshape((len(label),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006e03b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 40, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2, test_label2 = read_old_data()\n",
    "test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "457b49d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8646666407585144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(test2, test_label2, batch_size=batch_size, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a327e56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
